{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4162f299",
   "metadata": {},
   "source": [
    "# SourCandy Framework - Comprehensive Test Suite\n",
    "\n",
    "This notebook demonstrates all major features of the SourCandy framework for hallucination detection and correction.\n",
    "\n",
    "**Features Tested:**\n",
    "- LLM integration with OpenRouter\n",
    "- Knowledge graph construction\n",
    "- Document-based knowledge store\n",
    "- Token-level sourness calculation\n",
    "- Surgical correction\n",
    "- Domain verification\n",
    "- Prompt refinement\n",
    "- Metrics tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d8a67d",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "Install required dependencies (run if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0977aabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]\n",
      "NumPy version: 2.2.6\n",
      "Working directory: d:\\SourCandy_v1\\SourCandy\n"
     ]
    }
   ],
   "source": [
    "# Uncomment if you need to install dependencies\n",
    "# !pip install numpy requests openai\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeeb063",
   "metadata": {},
   "source": [
    "## 2. Import SourCandy Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaa11034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ All SourCandy components imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Core components\n",
    "from guard import Guard\n",
    "from core.embedding import SimpleEmbedder, BaseEmbedder\n",
    "from core.sournessIndex import SournessCalculator\n",
    "from knowledge.graph import KnowledgeGraph\n",
    "from knowledge.store import KnowledgeStore\n",
    "from verifiers.domainVerifiers import DomainVerifier, MultiDomainVerifier\n",
    "from correctors.fixes import SurgicalFixer\n",
    "from optimizers.promptRefiner import PromptRefiner\n",
    "from schema import SourCandyResponse, DiagnosticReport\n",
    "\n",
    "print(\"âœ“ All SourCandy components imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64082757",
   "metadata": {},
   "source": [
    "## 3. Configure OpenRouter LLM\n",
    "\n",
    "Set up the LLM client. Replace the placeholder with your actual API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1d9ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ LLM initialized with model: nvidia/nemotron-3-nano-30b-a3b:free\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# REPLACE WITH YOUR ACTUAL OPENROUTER API KEY\n",
    "OPENROUTER_API_KEY = \"\"\n",
    "\n",
    "# OpenRouter configuration\n",
    "openai.api_key = OPENROUTER_API_KEY\n",
    "openai.api_base = \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "# Model selection - choose based on your preference\n",
    "MODEL_NAME = \"nvidia/nemotron-3-nano-30b-a3b:free\"  # Fast and cost-effective\n",
    "# Alternative models:\n",
    "# MODEL_NAME = \"openai/gpt-3.5-turbo\"  # Good balance\n",
    "# MODEL_NAME = \"google/gemini-flash-1.5\"  # Fast Google model\n",
    "\n",
    "class OpenRouterLLM:\n",
    "    \"\"\"Wrapper for OpenRouter API compatible with SourCandy.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str, api_key: str):\n",
    "        self.model_name = model_name\n",
    "        self.client = openai.OpenAI(\n",
    "            api_key=api_key,\n",
    "            base_url=\"https://openrouter.ai/api/v1\"\n",
    "        )\n",
    "    \n",
    "    def invoke(self, prompt: str) -> Any:\n",
    "        \"\"\"Call OpenRouter API and return response.\"\"\"\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model_name,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=500,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"Error calling LLM: {e}\")\n",
    "            return f\"Error: {str(e)}\"\n",
    "    \n",
    "    def __call__(self, prompt: str) -> str:\n",
    "        return self.invoke(prompt)\n",
    "\n",
    "# Initialize LLM\n",
    "llm = OpenRouterLLM(MODEL_NAME, OPENROUTER_API_KEY)\n",
    "print(f\"âœ“ LLM initialized with model: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2270264",
   "metadata": {},
   "source": [
    "## 4. Create Knowledge Graph\n",
    "\n",
    "Build a knowledge graph with entities and relationships for grounding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "535b3bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Knowledge graph created with 8 entities\n",
      "âœ“ Added 6 relationships\n",
      "\n",
      "Sample entities: ['Python', 'NumPy', 'Pandas', 'Machine Learning', 'Neural Network']\n"
     ]
    }
   ],
   "source": [
    "# Initialize embedder and knowledge graph\n",
    "embedder = SimpleEmbedder(dimension=384)\n",
    "kg = KnowledgeGraph()\n",
    "\n",
    "# Add entities to knowledge graph - Example: Technology domain\n",
    "entities_data = [\n",
    "    {\"id\": \"python\", \"label\": \"Python\", \"text\": \"Python is a high-level programming language\"},\n",
    "    {\"id\": \"numpy\", \"label\": \"NumPy\", \"text\": \"NumPy is a library for numerical computing in Python\"},\n",
    "    {\"id\": \"pandas\", \"label\": \"Pandas\", \"text\": \"Pandas is a data analysis library for Python\"},\n",
    "    {\"id\": \"machine_learning\", \"label\": \"Machine Learning\", \"text\": \"Machine learning is a subset of artificial intelligence\"},\n",
    "    {\"id\": \"neural_network\", \"label\": \"Neural Network\", \"text\": \"Neural networks are computing systems inspired by biological neural networks\"},\n",
    "    {\"id\": \"transformer\", \"label\": \"Transformer\", \"text\": \"Transformers are neural network architectures using attention mechanisms\"},\n",
    "    {\"id\": \"llm\", \"label\": \"Large Language Model\", \"text\": \"LLMs are neural networks trained on vast amounts of text data\"},\n",
    "    {\"id\": \"hallucination\", \"label\": \"Hallucination\", \"text\": \"AI hallucinations are false or misleading outputs generated by language models\"},\n",
    "]\n",
    "\n",
    "# Add entities with embeddings\n",
    "for entity in entities_data:\n",
    "    embedding = embedder.embedText(entity[\"text\"])\n",
    "    kg.addEntity(entity[\"id\"], embedding, entity[\"label\"])\n",
    "\n",
    "# Add relationships\n",
    "relations = [\n",
    "    (\"numpy\", \"uses\", \"python\"),\n",
    "    (\"pandas\", \"uses\", \"python\"),\n",
    "    (\"neural_network\", \"part_of\", \"machine_learning\"),\n",
    "    (\"transformer\", \"type_of\", \"neural_network\"),\n",
    "    (\"llm\", \"uses\", \"transformer\"),\n",
    "    (\"hallucination\", \"occurs_in\", \"llm\"),\n",
    "]\n",
    "\n",
    "for subject, predicate, obj in relations:\n",
    "    kg.addRelation(subject, predicate, obj)\n",
    "\n",
    "print(f\"âœ“ Knowledge graph created with {len(kg.entities)} entities\")\n",
    "print(f\"âœ“ Added {len(relations)} relationships\")\n",
    "print(f\"\\nSample entities: {list(kg.entityLabels.values())[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e93cec",
   "metadata": {},
   "source": [
    "## 5. Add Knowledge Documents\n",
    "\n",
    "Populate the knowledge store with factual documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bf377ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Added 10 documents to knowledge store\n",
      "\n",
      "Test query: 'What is Python?'\n",
      "\n",
      "Top 3 similar documents:\n",
      "1. [0.165] Python is widely used for data science, web development, and automation....\n",
      "2. [0.161] Deep learning is a subset of machine learning that uses neural networks with mul...\n",
      "3. [0.143] The Transformer architecture was introduced in the 2017 paper 'Attention is All ...\n"
     ]
    }
   ],
   "source": [
    "# Create knowledge store\n",
    "knowledge_store = KnowledgeStore(embedder)\n",
    "\n",
    "# Add factual documents\n",
    "documents = [\n",
    "    \"Python was created by Guido van Rossum and first released in 1991.\",\n",
    "    \"NumPy provides support for large multi-dimensional arrays and matrices.\",\n",
    "    \"Pandas provides data structures like DataFrame for data manipulation and analysis.\",\n",
    "    \"Machine learning algorithms can learn from and make predictions on data.\",\n",
    "    \"Neural networks consist of layers of interconnected nodes called neurons.\",\n",
    "    \"The Transformer architecture was introduced in the 2017 paper 'Attention is All You Need'.\",\n",
    "    \"Large Language Models like GPT and Claude are trained on billions of parameters.\",\n",
    "    \"Hallucinations in AI occur when models generate plausible but incorrect information.\",\n",
    "    \"Python is widely used for data science, web development, and automation.\",\n",
    "    \"Deep learning is a subset of machine learning that uses neural networks with multiple layers.\",\n",
    "]\n",
    "\n",
    "metadata = [{\"source\": f\"doc_{i}\", \"verified\": True} for i in range(len(documents))]\n",
    "knowledge_store.addDocuments(documents, metadata)\n",
    "\n",
    "print(f\"âœ“ Added {len(documents)} documents to knowledge store\")\n",
    "\n",
    "# Test similarity search\n",
    "test_query = \"What is Python?\"\n",
    "results = knowledge_store.searchSimilar(test_query, topK=3)\n",
    "print(f\"\\nTest query: '{test_query}'\")\n",
    "print(\"\\nTop 3 similar documents:\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"{i}. [{result['score']:.3f}] {result['document'][:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7df5661",
   "metadata": {},
   "source": [
    "## 6. Initialize SourCandy Guard\n",
    "\n",
    "Set up the main Guard orchestrator with custom parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41802a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ SourCandy Guard initialized successfully\n",
      "  - Sourness threshold: 0.6\n",
      "  - Weights: w1=0.5, w2=0.3, w3=0.2\n"
     ]
    }
   ],
   "source": [
    "# Initialize Guard with custom sourness threshold and weights\n",
    "guard = Guard(\n",
    "    baseLlm=llm,\n",
    "    knowledgeGraph=kg,\n",
    "    embedder=embedder,\n",
    "    sournessThreshold=0.6,  # Tokens above this are considered \"sour\"\n",
    "    w1=0.5,  # Weight for knowledge grounding\n",
    "    w2=0.3,  # Weight for prompt correspondence\n",
    "    w3=0.2   # Weight for relational connectivity\n",
    ")\n",
    "\n",
    "# Add knowledge documents to the guard\n",
    "guard.addKnowledgeDocuments(documents, metadata)\n",
    "\n",
    "print(\"âœ“ SourCandy Guard initialized successfully\")\n",
    "print(f\"  - Sourness threshold: {guard.sournessThreshold}\")\n",
    "print(f\"  - Weights: w1={guard.sournessCalculator.w1}, w2={guard.sournessCalculator.w2}, w3={guard.sournessCalculator.w3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e776f89",
   "metadata": {},
   "source": [
    "## 7. Add Domain Verifier\n",
    "\n",
    "Configure domain-specific verification rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "259fa64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Domain verifier added for 'technology' domain\n",
      "  - Keywords: 9 registered\n",
      "  - Entity similarity threshold: 0.7\n"
     ]
    }
   ],
   "source": [
    "# Create domain verifier for technology/AI domain\n",
    "tech_verifier = DomainVerifier(\n",
    "    domain=\"technology\",\n",
    "    knowledgeGraph=kg,\n",
    "    knowledgeStore=knowledge_store,\n",
    "    embedder=embedder,\n",
    "    entitySimilarityThreshold=0.7,\n",
    "    claimSimilarityThreshold=0.6,\n",
    "    sournessThreshold=0.7,\n",
    "    clusterSize=3\n",
    ")\n",
    "\n",
    "# Add domain keywords\n",
    "tech_keywords = [\n",
    "    \"python\", \"programming\", \"machine learning\", \"neural network\",\n",
    "    \"transformer\", \"AI\", \"data science\", \"numpy\", \"pandas\"\n",
    "]\n",
    "tech_verifier.addDomainKeywords(tech_keywords)\n",
    "\n",
    "# Add to guard\n",
    "guard.addDomainVerifier(\"technology\", tech_verifier)\n",
    "\n",
    "print(\"âœ“ Domain verifier added for 'technology' domain\")\n",
    "print(f\"  - Keywords: {len(tech_keywords)} registered\")\n",
    "print(f\"  - Entity similarity threshold: {tech_verifier.entitySimilarityThreshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ff86d5",
   "metadata": {},
   "source": [
    "## 8. Test Basic Guard Invocation\n",
    "\n",
    "Run a simple test to see sourness detection in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00c17536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with prompt: 'Explain what Python is and its main uses.'\n",
      "\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š RESULTS:\n",
      "============================================================\n",
      "\n",
      "âœ“ Is Sweet (No hallucinations): False\n",
      "\n",
      "ðŸ“ Final Content:\n",
      "**Improved version**\n",
      "\n",
      "Python is a highâ€‘level, interpreted programming language that has become the deâ€‘facto standard for machine learning, data analysis, and the development of transformerâ€‘based models. Its ecosystem includes core libraries such as **NumPy** for numerical computation, **Pandas** for data manipulation, and extensive support for **neural networks** and **Transformer architectures**.  \n",
      "\n",
      "In naturalâ€‘language processing, Python is used to implement and fine\n",
      "\n",
      "ðŸ“ˆ Aggregate Sourness Score: 0.665\n",
      "\n",
      "âš ï¸  Hallucinations Detected: 146\n",
      "\n",
      "Hallucinations:\n",
      "  - High sourness region: automation | Selenium,\n",
      "  - High sourness region: **DevOps & Cloud**\n",
      "  - High sourness region: for file I/O,\n",
      "  - High sourness region: can run Python\n",
      "  - High sourness region: Computing** | Simulations,\n",
      "  - High sourness region: | Ansible, Fabric,\n",
      "  - High sourness region: Popular Libraries /\n",
      "  - Unverified entity: Web Development\n",
      "  - High sourness region: without a separate\n",
      "  - High sourness region: | |---------|----------------| |\n",
      "  - High sourness region: | **Interpreted** |\n",
      "  - High sourness region: | Data cleaning,\n",
      "  - Unverified entity: What Python Is\n",
      "  - Unverified entity: Runs\n",
      "  - Unverified entity: Selenium\n",
      "  - High sourness region: | | **Interpreted**\n",
      "  - High sourness region: System admin tasks,\n",
      "  - High sourness region: development cycles; you\n",
      "  - High sourness region: â€œBatteriesâ€‘includedâ€ modules for\n",
      "  - High sourness region: BeautifulSoup, Requests, PyAutoGUI\n",
      "  - High sourness region: Flask, FastAPI, Tornado\n",
      "  - Unverified entity: Ansible\n",
      "  - High sourness region: Simulations, numerical analysis,\n",
      "  - High sourness region: modules for file\n",
      "  - Unverified entity: Apps\n",
      "  - Unverified entity: Automation\n",
      "  - Unverified entity: Open\n",
      "  - High sourness region: released in 1991.\n",
      "  - High sourness region: PyAutoGUI | |\n",
      "  - Unverified entity: Scientific Computing\n",
      "  - Unverified entity: Interpreted\n",
      "  - High sourness region: typing** | You\n",
      "  - High sourness region: design philosophy emphasizes\n",
      "  - High sourness region: | Why It\n",
      "  - High sourness region: source** | A\n",
      "  - Unverified entity: Keras\n",
      "  - High sourness region: step, which makes\n",
      "  - High sourness region: Libraries / Frameworks\n",
      "  - High sourness region: A huge, active\n",
      "  - Unverified entity: Faster\n",
      "  - Unverified entity: Scripting\n",
      "  - Unverified entity: Main Uses\n",
      "  - Unverified entity: Machine Learning\n",
      "  - Unverified entity: Docker\n",
      "  - High sourness region: analysis | pandas,\n",
      "  - High sourness region: on Windows, macOS,\n",
      "  - High sourness region: Matters | |---------|----------------|\n",
      "  - High sourness region: Why It Matters\n",
      "  - High sourness region: external packages for\n",
      "  - High sourness region: figures them out\n",
      "  - Unverified entity: Cloud\n",
      "  - High sourness region: It Matters |\n",
      "  - High sourness region: **Interpreted** | Faster\n",
      "  - Unverified entity: Flask\n",
      "  - High sourness region: / Frameworks |\n",
      "  - High sourness region: modeling, exploratory analysis\n",
      "  - High sourness region: cycles; you can\n",
      "  - Unverified entity: Requests\n",
      "  - High sourness region: **Open source** |\n",
      "  - High sourness region: |---------|----------------| | **Dynamic\n",
      "  - High sourness region: Analytics** | Data\n",
      "  - High sourness region: interpreter figures them\n",
      "  - Unverified entity: Cross\n",
      "  - High sourness region: | --- **Main\n",
      "  - High sourness region: experimentation easy. Key\n",
      "  - High sourness region: numerical analysis, computational\n",
      "  - Unverified entity: Rossum\n",
      "  - Unverified entity: Frameworks\n",
      "  - High sourness region: | | **Open\n",
      "  - High sourness region: **Scientific Computing** |\n",
      "  - High sourness region: exploratory analysis |\n",
      "  - High sourness region: packages for basic\n",
      "  - Unverified entity: Data Science\n",
      "  - High sourness region: | **Dynamic typing**\n",
      "  - High sourness region: AI** | Model\n",
      "  - Unverified entity: Windows\n",
      "  - Unverified entity: English\n",
      "  - High sourness region: | Runs on\n",
      "  - Unverified entity: Kivy\n",
      "  - Unverified entity: Feature\n",
      "  - Unverified entity: Model\n",
      "  - High sourness region: easy. Key characteristics:\n",
      "  - High sourness region: analysis, computational physics\n",
      "  - High sourness region: tools | Tkinter,\n",
      "  - High sourness region: out at runtime.\n",
      "  - Unverified entity: System\n",
      "  - High sourness region: Runs on Windows,\n",
      "  - High sourness region: & Cloud** |\n",
      "  - Unverified entity: Analytics\n",
      "  - Unverified entity: Typical Applications\n",
      "  - Unverified entity: Why It Matters\n",
      "  - High sourness region: you can run\n",
      "  - High sourness region: **Automation & Scripting**\n",
      "  - Unverified entity: Tkinter\n",
      "  - High sourness region: I/O, networking, testing,\n",
      "  - Unverified entity: Tornado\n",
      "  - High sourness region: FastAPI, Tornado |\n",
      "  - Unverified entity: Because\n",
      "  - High sourness region: computational physics |\n",
      "  - High sourness region: characteristics: | Feature\n",
      "  - High sourness region: Key characteristics: |\n",
      "  - High sourness region: Model training, inference,\n",
      "  - Unverified entity: Backend\n",
      "  - Unverified entity: Linux\n",
      "  - High sourness region: file I/O, networking,\n",
      "  - Unverified entity: Domain\n",
      "  - High sourness region: so you often\n",
      "  - High sourness region: Feature | Why\n",
      "  - High sourness region: Data cleaning, statistical\n",
      "  - High sourness region: | Popular Libraries\n",
      "  - Unverified entity: Python\n",
      "  - High sourness region: compilation step, which\n",
      "  - High sourness region: contributes libraries, tools,\n",
      "  - High sourness region: highâ€‘level, interpreted programming\n",
      "  - High sourness region: | Feature |\n",
      "  - High sourness region: them out at\n",
      "  - High sourness region: can run scripts\n",
      "  - High sourness region: Selenium, BeautifulSoup, Requests,\n",
      "  - Unverified entity: Fabric\n",
      "  - Unverified entity: Infrastructure\n",
      "  - High sourness region: modification. | |\n",
      "  - High sourness region: | Model training,\n",
      "  - Unverified entity: Desktop\n",
      "  - Unverified entity: Rich\n",
      "  - Unverified entity: Batteries\n",
      "  - Unverified entity: Popular Libraries\n",
      "  - High sourness region: without modification. |\n",
      "  - High sourness region: statistical modeling, exploratory\n",
      "  - High sourness region: | Selenium, BeautifulSoup,\n",
      "  - High sourness region: desktop tools |\n",
      "  - High sourness region: documentation. | ---\n",
      "  - Unverified entity: Dynamic\n",
      "  - High sourness region: philosophy emphasizes **readability**\n",
      "  - Unverified entity: Data\n",
      "  - High sourness region: & Scripting** |\n",
      "  - Unverified entity: Guido\n",
      "  - High sourness region: Ansible, Fabric, AWS\n",
      "  - High sourness region: | A huge,\n",
      "  - Unverified entity: Simulations\n",
      "  - Unverified entity: Django\n",
      "  - High sourness region: **Dynamic typing** |\n",
      "  - High sourness region: Development** | Backend\n",
      "  - High sourness region: Requests, PyAutoGUI |\n",
      "  - High sourness region: | â€œBatteriesâ€‘includedâ€ modules\n",
      "  - High sourness region: admin tasks, web\n",
      "  - High sourness region: **Main Uses of\n"
     ]
    }
   ],
   "source": [
    "# Test prompt\n",
    "test_prompt = \"Explain what Python is and its main uses.\"\n",
    "\n",
    "print(f\"Testing with prompt: '{test_prompt}'\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Invoke guard with all features enabled\n",
    "response = guard.invoke(\n",
    "    prompt=test_prompt,\n",
    "    enableCorrection=True,\n",
    "    enableVerification=True,\n",
    "    returnDiagnostics=True\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ“Š RESULTS:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nâœ“ Is Sweet (No hallucinations): {response.isSweet}\")\n",
    "print(f\"\\nðŸ“ Final Content:\\n{response.finalContent}\")\n",
    "print(f\"\\nðŸ“ˆ Aggregate Sourness Score: {response.diagnosticReport.sournessMap.aggregateSournessScore:.3f}\")\n",
    "print(f\"\\nâš ï¸  Hallucinations Detected: {len(response.diagnosticReport.identifiedHallucinations)}\")\n",
    "\n",
    "if response.diagnosticReport.identifiedHallucinations:\n",
    "    print(\"\\nHallucinations:\")\n",
    "    for h in response.diagnosticReport.identifiedHallucinations:\n",
    "        print(f\"  - {h}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2625a693",
   "metadata": {},
   "source": [
    "## 9. Detailed Sourness Analysis\n",
    "\n",
    "Examine token-level sourness scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a95e8f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKEN-LEVEL SOURNESS ANALYSIS:\n",
      "============================================================\n",
      "\n",
      "Total tokens analyzed: 290\n",
      "Sourness threshold: 0.6\n",
      "\n",
      "Top 10 'Sourest' Tokens:\n",
      "------------------------------------------------------------\n",
      " 1. them                 | Score: 0.7714 | âš ï¸ SOUR\n",
      " 2. contributes          | Score: 0.7706 | âš ï¸ SOUR\n",
      " 3. an                   | Score: 0.7701 | âš ï¸ SOUR\n",
      " 4. FastAPI,             | Score: 0.7683 | âš ï¸ SOUR\n",
      " 5. tasks,               | Score: 0.7681 | âš ï¸ SOUR\n",
      " 6. **Data               | Score: 0.7671 | âš ï¸ SOUR\n",
      " 7. Cloud**              | Score: 0.7664 | âš ï¸ SOUR\n",
      " 8. so                   | Score: 0.7653 | âš ï¸ SOUR\n",
      " 9. which                | Score: 0.7644 | âš ï¸ SOUR\n",
      "10. interpreted          | Score: 0.7642 | âš ï¸ SOUR\n",
      "\n",
      "ðŸ“Š Statistics:\n",
      "  - Sour tokens: 250 (86.2%)\n",
      "  - Sweet tokens: 40 (13.8%)\n",
      "  - Average sourness: 0.6646\n"
     ]
    }
   ],
   "source": [
    "# Display token-level diagnostics\n",
    "print(\"TOKEN-LEVEL SOURNESS ANALYSIS:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "diagnostics = response.diagnosticReport.sournessMap.tokenDiagnostics\n",
    "\n",
    "print(f\"\\nTotal tokens analyzed: {len(diagnostics)}\")\n",
    "print(f\"Sourness threshold: {guard.sournessThreshold}\\n\")\n",
    "\n",
    "# Show tokens with highest sourness\n",
    "sorted_diagnostics = sorted(diagnostics, key=lambda d: d.sournessScore, reverse=True)\n",
    "\n",
    "print(\"Top 10 'Sourest' Tokens:\")\n",
    "print(\"-\" * 60)\n",
    "for i, diag in enumerate(sorted_diagnostics[:10], 1):\n",
    "    status = \"âš ï¸ SOUR\" if diag.sournessScore > guard.sournessThreshold else \"âœ“ Sweet\"\n",
    "    print(f\"{i:2}. {diag.token:20} | Score: {diag.sournessScore:.4f} | {status}\")\n",
    "\n",
    "# Calculate statistics\n",
    "sour_tokens = [d for d in diagnostics if d.sournessScore > guard.sournessThreshold]\n",
    "sweet_tokens = [d for d in diagnostics if d.sournessScore <= guard.sournessThreshold]\n",
    "\n",
    "print(f\"\\nðŸ“Š Statistics:\")\n",
    "print(f\"  - Sour tokens: {len(sour_tokens)} ({len(sour_tokens)/len(diagnostics)*100:.1f}%)\")\n",
    "print(f\"  - Sweet tokens: {len(sweet_tokens)} ({len(sweet_tokens)/len(diagnostics)*100:.1f}%)\")\n",
    "print(f\"  - Average sourness: {response.diagnosticReport.sournessMap.aggregateSournessScore:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6aed43",
   "metadata": {},
   "source": [
    "## 10. Test with Different Prompts\n",
    "\n",
    "Compare responses with varying complexity and factual accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9623f677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING MULTIPLE PROMPTS:\n",
      "============================================================\n",
      "\n",
      "1. Testing: 'What is NumPy used for?'\n",
      "   Sweet: False | Sourness: 0.675 | Hallucinations: 155\n",
      "\n",
      "2. Testing: 'Explain how transformers work in machine learning.'\n",
      "   Sweet: False | Sourness: 0.675 | Hallucinations: 117\n",
      "\n",
      "3. Testing: 'What causes hallucinations in large language models?'\n",
      "   Sweet: False | Sourness: 0.681 | Hallucinations: 156\n",
      "\n",
      "============================================================\n",
      "SUMMARY:\n",
      "============================================================\n",
      "Average sourness: 0.677\n",
      "Total hallucinations: 428\n",
      "Sweet responses: 0/3\n"
     ]
    }
   ],
   "source": [
    "# Test with multiple prompts\n",
    "test_prompts = [\n",
    "    \"What is NumPy used for?\",\n",
    "    \"Explain how transformers work in machine learning.\",\n",
    "    \"What causes hallucinations in large language models?\",\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"TESTING MULTIPLE PROMPTS:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, prompt in enumerate(test_prompts, 1):\n",
    "    print(f\"\\n{i}. Testing: '{prompt}'\")\n",
    "    \n",
    "    response = guard.invoke(\n",
    "        prompt=prompt,\n",
    "        enableCorrection=True,\n",
    "        enableVerification=True\n",
    "    )\n",
    "    \n",
    "    results.append({\n",
    "        'prompt': prompt,\n",
    "        'isSweet': response.isSweet,\n",
    "        'sourness': response.diagnosticReport.sournessMap.aggregateSournessScore,\n",
    "        'hallucinations': len(response.diagnosticReport.identifiedHallucinations)\n",
    "    })\n",
    "    \n",
    "    print(f\"   Sweet: {response.isSweet} | Sourness: {response.diagnosticReport.sournessMap.aggregateSournessScore:.3f} | Hallucinations: {len(response.diagnosticReport.identifiedHallucinations)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY:\")\n",
    "print(\"=\"*60)\n",
    "avg_sourness = sum(r['sourness'] for r in results) / len(results)\n",
    "total_hallucinations = sum(r['hallucinations'] for r in results)\n",
    "sweet_count = sum(1 for r in results if r['isSweet'])\n",
    "\n",
    "print(f\"Average sourness: {avg_sourness:.3f}\")\n",
    "print(f\"Total hallucinations: {total_hallucinations}\")\n",
    "print(f\"Sweet responses: {sweet_count}/{len(results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74202a6",
   "metadata": {},
   "source": [
    "## 11. Test Correction Features\n",
    "\n",
    "Compare outputs with and without correction enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85b6d0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTION COMPARISON TEST:\n",
      "============================================================\n",
      "\n",
      "Prompt: 'Describe the relationship between Python and machine learning libraries.'\n",
      "\n",
      "\n",
      "1ï¸âƒ£  WITHOUT CORRECTION:\n",
      "------------------------------------------------------------\n",
      "Raw output: ## Pythonâ€¯â†”â€¯Machineâ€‘Learning Libraries: How They Fit Together\n",
      "\n",
      "| **Aspect** | **What it means** | **Typical Python libraries** |\n",
      "|------------|-------------------|------------------------------|\n",
      "| **Python as the foundation** | Python is a highâ€‘level, interpreted programming language that emphasizes readability and rapid development. Its dynamic typing, extensive standard library, and massive ecosystem of thirdâ€‘party packages make it ideal for dataâ€‘oriented work. | â€” |\n",
      "| **Core scientific stack** | These packages provide the numerical and dataâ€‘handling primitives that almost every ML workflow relies on. | **NumPy** â€“ efficient multiâ€‘dimensional arrays; **pandas** â€“ tabular data structures (DataFrames) with rich I/O and manipulation; **scipy** â€“ scientific algorithms (optimisation, linear algebra, statistics); **matplotlib / seaborn / plotly** â€“ visualisation. |\n",
      "| **Dataâ€‘preâ€‘processing & feature engineering** | Realâ€‘world data must be cleaned, transformed, and encoded before it can be fed to a model. | **pandas**, **scikitâ€‘learn** (`preprocessing`, `pipeline`, `feature_selection`), **category_encoders**, **imbalancedâ€‘learn** (for resampling). |\n",
      "| **Model building & evaluation** | The â€œmachineâ€‘learning engineâ€ where algorithms are instantiated, trained, tuned, and validated. | **scikitâ€‘learn** â€“ classical algorithms (linear models, SVMs, trees, ensembles, clustering); **TensorFlow** / **Keras** â€“ lowâ€‘level (TensorFlow) and highâ€‘level (Keras) deepâ€‘learning APIs; **PyTorch** â€“ dynamic graph deep learning; **XGBoost / LightGBM / CatBoost**\n",
      "Sourness: 0.682\n",
      "\n",
      "2ï¸âƒ£  WITH CORRECTION:\n",
      "------------------------------------------------------------\n",
      "Corrected output: **Improved version**\n",
      "\n",
      "Python is a generalâ€‘purpose programming language that has become the deâ€‘facto foundation for modern machineâ€‘learning work. Its ecosystem includes a variety of specialized libraries that handle different stages of the ML pipeline:\n",
      "\n",
      "- **NumPy** provides efficient numerical operations and linearâ€‘algebra primitives, making it the backbone for arrayâ€‘based computations in Python.  \n",
      "- **Pandas** builds on NumPy to offer highâ€‘level dataâ€‘frame structures and manipulation tools, enabling clean data loading, cleaning, and exploratory analysis.  \n",
      "- **Transformer** architectures are a\n",
      "Sourness: 0.674\n",
      "\n",
      "============================================================\n",
      "Improvement: Correction attempted to improve output quality\n"
     ]
    }
   ],
   "source": [
    "comparison_prompt = \"Describe the relationship between Python and machine learning libraries.\"\n",
    "\n",
    "print(\"CORRECTION COMPARISON TEST:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nPrompt: '{comparison_prompt}'\\n\")\n",
    "\n",
    "# Without correction\n",
    "print(\"\\n1ï¸âƒ£  WITHOUT CORRECTION:\")\n",
    "print(\"-\" * 60)\n",
    "response_no_correction = guard.invoke(\n",
    "    prompt=comparison_prompt,\n",
    "    enableCorrection=False,\n",
    "    enableVerification=True\n",
    ")\n",
    "print(f\"Raw output: {response_no_correction.diagnosticReport.rawOutput}\")\n",
    "print(f\"Sourness: {response_no_correction.diagnosticReport.sournessMap.aggregateSournessScore:.3f}\")\n",
    "\n",
    "# With correction\n",
    "print(\"\\n2ï¸âƒ£  WITH CORRECTION:\")\n",
    "print(\"-\" * 60)\n",
    "response_with_correction = guard.invoke(\n",
    "    prompt=comparison_prompt,\n",
    "    enableCorrection=True,\n",
    "    enableVerification=True\n",
    ")\n",
    "print(f\"Corrected output: {response_with_correction.finalContent}\")\n",
    "print(f\"Sourness: {response_with_correction.diagnosticReport.sournessMap.aggregateSournessScore:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Improvement: Correction {'improved' if response_with_correction.isSweet else 'attempted to improve'} output quality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dece748",
   "metadata": {},
   "source": [
    "## 12. Metrics Tracking\n",
    "\n",
    "View aggregated metrics across all runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0efc701c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGGREGATED METRICS:\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š Overall Performance:\n",
      "  Total runs: 6\n",
      "  Average sourness: 0.6753\n",
      "  Sweet rate: 0.00%\n",
      "  Sweet count: 0/6\n",
      "  Total hallucinations: 779\n",
      "  Avg hallucinations per run: 129.83\n",
      "\n",
      "ðŸ“œ Run History:\n",
      "------------------------------------------------------------\n",
      "\n",
      "Run 1:\n",
      "  Prompt: What is NumPy used for?...\n",
      "  Sourness: 0.675\n",
      "  Hallucinations: 155\n",
      "  Sweet: False\n",
      "\n",
      "Run 2:\n",
      "  Prompt: Explain how transformers work in machine learning....\n",
      "  Sourness: 0.675\n",
      "  Hallucinations: 117\n",
      "  Sweet: False\n",
      "\n",
      "Run 3:\n",
      "  Prompt: What causes hallucinations in large language model...\n",
      "  Sourness: 0.681\n",
      "  Hallucinations: 156\n",
      "  Sweet: False\n",
      "\n",
      "Run 4:\n",
      "  Prompt: Describe the relationship between Python and machi...\n",
      "  Sourness: 0.682\n",
      "  Hallucinations: 94\n",
      "  Sweet: False\n",
      "\n",
      "Run 5:\n",
      "  Prompt: Describe the relationship between Python and machi...\n",
      "  Sourness: 0.674\n",
      "  Hallucinations: 111\n",
      "  Sweet: False\n"
     ]
    }
   ],
   "source": [
    "# Get metrics\n",
    "metrics = guard.getMetrics()\n",
    "\n",
    "print(\"AGGREGATED METRICS:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nðŸ“Š Overall Performance:\")\n",
    "print(f\"  Total runs: {metrics['totalRuns']}\")\n",
    "print(f\"  Average sourness: {metrics['averageSourness']:.4f}\")\n",
    "print(f\"  Sweet rate: {metrics['sweetRate']:.2%}\")\n",
    "print(f\"  Sweet count: {metrics['sweetCount']}/{metrics['totalRuns']}\")\n",
    "print(f\"  Total hallucinations: {metrics['totalHallucinations']}\")\n",
    "print(f\"  Avg hallucinations per run: {metrics['averageHallucinationsPerRun']:.2f}\")\n",
    "\n",
    "# Display run history\n",
    "print(\"\\nðŸ“œ Run History:\")\n",
    "print(\"-\" * 60)\n",
    "for i, run in enumerate(guard.runHistory[-5:], 1):  # Show last 5 runs\n",
    "    print(f\"\\nRun {i}:\")\n",
    "    print(f\"  Prompt: {run['prompt'][:50]}...\")\n",
    "    print(f\"  Sourness: {run['aggregateSourness']:.3f}\")\n",
    "    print(f\"  Hallucinations: {run['hallucinationCount']}\")\n",
    "    print(f\"  Sweet: {run['isSweet']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1f9381",
   "metadata": {},
   "source": [
    "## 13. Prompt Refinement\n",
    "\n",
    "Test the automatic prompt optimization feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f2b1132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT REFINEMENT TEST:\n",
      "============================================================\n",
      "\n",
      "Original prompt: 'Tell me about neural networks and their applications.'\n",
      "\n",
      "Initial sourness: 0.674\n",
      "Hallucinations found: 152\n",
      "\n",
      "ðŸ“ Refined Prompt:\n",
      "------------------------------------------------------------\n",
      "**Optimized System Prompt**\n",
      "\n",
      "You are an expert AI assistant trained to\n",
      "\n",
      "Tell me about neural networks and their applications.\n",
      "\n",
      "ðŸ”„ Testing with refined prompt...\n",
      "\n",
      "Refined sourness: 0.679\n",
      "Hallucinations found: 157\n",
      "\n",
      "â†’ No significant improvement (may indicate good initial prompt)\n"
     ]
    }
   ],
   "source": [
    "# Get a response with diagnostics\n",
    "original_prompt = \"Tell me about neural networks and their applications.\"\n",
    "\n",
    "print(\"PROMPT REFINEMENT TEST:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nOriginal prompt: '{original_prompt}'\\n\")\n",
    "\n",
    "initial_response = guard.invoke(\n",
    "    prompt=original_prompt,\n",
    "    enableCorrection=True,\n",
    "    enableVerification=True,\n",
    "    returnDiagnostics=True\n",
    ")\n",
    "\n",
    "print(f\"Initial sourness: {initial_response.diagnosticReport.sournessMap.aggregateSournessScore:.3f}\")\n",
    "print(f\"Hallucinations found: {len(initial_response.diagnosticReport.identifiedHallucinations)}\")\n",
    "\n",
    "# Generate refined prompt\n",
    "refined_prompt = guard.refinePrompt(original_prompt, initial_response.diagnosticReport)\n",
    "\n",
    "print(\"\\nðŸ“ Refined Prompt:\")\n",
    "print(\"-\" * 60)\n",
    "print(refined_prompt)\n",
    "\n",
    "# Test with refined prompt\n",
    "print(\"\\nðŸ”„ Testing with refined prompt...\")\n",
    "refined_response = guard.invoke(\n",
    "    prompt=refined_prompt,\n",
    "    enableCorrection=True,\n",
    "    enableVerification=True\n",
    ")\n",
    "\n",
    "print(f\"\\nRefined sourness: {refined_response.diagnosticReport.sournessMap.aggregateSournessScore:.3f}\")\n",
    "print(f\"Hallucinations found: {len(refined_response.diagnosticReport.identifiedHallucinations)}\")\n",
    "\n",
    "if initial_response.diagnosticReport.sournessMap.aggregateSournessScore > refined_response.diagnosticReport.sournessMap.aggregateSournessScore:\n",
    "    improvement = initial_response.diagnosticReport.sournessMap.aggregateSournessScore - refined_response.diagnosticReport.sournessMap.aggregateSournessScore\n",
    "    print(f\"\\nâœ“ Improvement: {improvement:.3f} reduction in sourness\")\n",
    "else:\n",
    "    print(\"\\nâ†’ No significant improvement (may indicate good initial prompt)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9c75a3",
   "metadata": {},
   "source": [
    "## 14. Batch Processing\n",
    "\n",
    "Process multiple prompts efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c994ae90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH PROCESSING TEST:\n",
      "============================================================\n",
      "\n",
      "Processing 3 prompts...\n",
      "\n",
      "1. Prompt: 'What is the purpose of Pandas library?'\n",
      "   Sweet: False\n",
      "   Sourness: 0.673\n",
      "   Output: ...\n",
      "\n",
      "2. Prompt: 'How do attention mechanisms work in transformers?'\n",
      "   Sweet: False\n",
      "   Sourness: 0.676\n",
      "   Output: ...\n",
      "\n",
      "3. Prompt: 'What programming language is best for data science?'\n",
      "   Sweet: False\n",
      "   Sourness: 0.678\n",
      "   Output: ...\n",
      "\n",
      "============================================================\n",
      "Batch processing complete: 3/3 processed\n"
     ]
    }
   ],
   "source": [
    "# Batch prompts\n",
    "batch_prompts = [\n",
    "    \"What is the purpose of Pandas library?\",\n",
    "    \"How do attention mechanisms work in transformers?\",\n",
    "    \"What programming language is best for data science?\",\n",
    "]\n",
    "\n",
    "print(\"BATCH PROCESSING TEST:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nProcessing {len(batch_prompts)} prompts...\\n\")\n",
    "\n",
    "# Process batch\n",
    "batch_results = guard.batchInvoke(\n",
    "    prompts=batch_prompts,\n",
    "    enableCorrection=True,\n",
    "    enableVerification=True\n",
    ")\n",
    "\n",
    "# Display results\n",
    "for i, (prompt, response) in enumerate(zip(batch_prompts, batch_results), 1):\n",
    "    print(f\"{i}. Prompt: '{prompt}'\")\n",
    "    print(f\"   Sweet: {response.isSweet}\")\n",
    "    print(f\"   Sourness: {response.diagnosticReport.sournessMap.aggregateSournessScore:.3f}\")\n",
    "    print(f\"   Output: {response.finalContent[:100]}...\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"Batch processing complete: {len(batch_results)}/{len(batch_prompts)} processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f9e702",
   "metadata": {},
   "source": [
    "## 15. Custom Configuration Test\n",
    "\n",
    "Test different sourness thresholds and weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12a380a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUSTOM CONFIGURATION TEST:\n",
      "============================================================\n",
      "\n",
      "Strict Configuration:\n",
      "  Threshold: 0.4, Weights: (0.6, 0.3, 0.1)\n",
      "  Result - Sweet: False, Sourness: 0.714\n",
      "\n",
      "Balanced Configuration:\n",
      "  Threshold: 0.6, Weights: (0.5, 0.3, 0.2)\n",
      "  Result - Sweet: False, Sourness: 0.677\n",
      "\n",
      "Lenient Configuration:\n",
      "  Threshold: 0.8, Weights: (0.4, 0.4, 0.2)\n",
      "  Result - Sweet: True, Sourness: 0.648\n",
      "\n",
      "============================================================\n",
      "Configuration comparison complete\n"
     ]
    }
   ],
   "source": [
    "print(\"CUSTOM CONFIGURATION TEST:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test different configurations\n",
    "configurations = [\n",
    "    {\"name\": \"Strict\", \"threshold\": 0.4, \"w1\": 0.6, \"w2\": 0.3, \"w3\": 0.1},\n",
    "    {\"name\": \"Balanced\", \"threshold\": 0.6, \"w1\": 0.5, \"w2\": 0.3, \"w3\": 0.2},\n",
    "    {\"name\": \"Lenient\", \"threshold\": 0.8, \"w1\": 0.4, \"w2\": 0.4, \"w3\": 0.2},\n",
    "]\n",
    "\n",
    "test_prompt = \"Explain what makes Python popular for machine learning.\"\n",
    "\n",
    "for config in configurations:\n",
    "    print(f\"\\n{config['name']} Configuration:\")\n",
    "    print(f\"  Threshold: {config['threshold']}, Weights: ({config['w1']}, {config['w2']}, {config['w3']})\")\n",
    "    \n",
    "    # Create guard with custom config\n",
    "    custom_guard = Guard(\n",
    "        baseLlm=llm,\n",
    "        knowledgeGraph=kg,\n",
    "        embedder=embedder,\n",
    "        sournessThreshold=config['threshold'],\n",
    "        w1=config['w1'],\n",
    "        w2=config['w2'],\n",
    "        w3=config['w3']\n",
    "    )\n",
    "    custom_guard.addKnowledgeDocuments(documents)\n",
    "    \n",
    "    response = custom_guard.invoke(test_prompt, enableCorrection=True)\n",
    "    \n",
    "    print(f\"  Result - Sweet: {response.isSweet}, Sourness: {response.diagnosticReport.sournessMap.aggregateSournessScore:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Configuration comparison complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb784ae",
   "metadata": {},
   "source": [
    "## 16. Optimization Suggestions\n",
    "\n",
    "Review automated optimization recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba1cce13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPTIMIZATION SUGGESTIONS:\n",
      "============================================================\n",
      "\n",
      "Prompt: 'How does deep learning differ from traditional machine learning?'\n",
      "\n",
      "ðŸ’¡ Suggestions:\n",
      "Multiple hallucinations found (165). Review domain verifier constraints.\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Get optimization suggestions\n",
    "print(\"OPTIMIZATION SUGGESTIONS:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_prompt = \"How does deep learning differ from traditional machine learning?\"\n",
    "response = guard.invoke(test_prompt, returnDiagnostics=True)\n",
    "\n",
    "if response.diagnosticReport.optimizationSuggestion:\n",
    "    print(f\"\\nPrompt: '{test_prompt}'\")\n",
    "    print(f\"\\nðŸ’¡ Suggestions:\")\n",
    "    print(response.diagnosticReport.optimizationSuggestion)\n",
    "else:\n",
    "    print(\"\\nâœ“ No optimization needed - output quality is good!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76687324",
   "metadata": {},
   "source": [
    "## 17. Final Summary\n",
    "\n",
    "Review complete test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfe77863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "               FINAL TEST SUMMARY\n",
      "============================================================\n",
      "\n",
      "âœ… Components Tested:\n",
      "  âœ“ LLM Integration (OpenRouter)\n",
      "  âœ“ Knowledge Graph Construction\n",
      "  âœ“ Document Knowledge Store\n",
      "  âœ“ Token Sourness Analysis\n",
      "  âœ“ Surgical Correction\n",
      "  âœ“ Domain Verification\n",
      "  âœ“ Prompt Refinement\n",
      "  âœ“ Batch Processing\n",
      "  âœ“ Metrics Tracking\n",
      "  âœ“ Custom Configurations\n",
      "\n",
      "ðŸ“Š Session Statistics:\n",
      "  Total LLM calls: 12\n",
      "  Average sourness: 0.6761\n",
      "  Success rate (sweet): 0.0%\n",
      "  Total hallucinations detected: 1658\n",
      "\n",
      "ðŸŽ¯ Framework Capabilities Validated:\n",
      "  â†’ Production-grade error handling\n",
      "  â†’ Configurable thresholds and weights\n",
      "  â†’ Comprehensive validation\n",
      "  â†’ Token-level diagnostics\n",
      "  â†’ Automated corrections\n",
      "\n",
      "============================================================\n",
      "âœ¨ SourCandy Framework Test Complete!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Final metrics\n",
    "final_metrics = guard.getMetrics()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" \" * 15 + \"FINAL TEST SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nâœ… Components Tested:\")\n",
    "print(\"  âœ“ LLM Integration (OpenRouter)\")\n",
    "print(\"  âœ“ Knowledge Graph Construction\")\n",
    "print(\"  âœ“ Document Knowledge Store\")\n",
    "print(\"  âœ“ Token Sourness Analysis\")\n",
    "print(\"  âœ“ Surgical Correction\")\n",
    "print(\"  âœ“ Domain Verification\")\n",
    "print(\"  âœ“ Prompt Refinement\")\n",
    "print(\"  âœ“ Batch Processing\")\n",
    "print(\"  âœ“ Metrics Tracking\")\n",
    "print(\"  âœ“ Custom Configurations\")\n",
    "\n",
    "print(\"\\nðŸ“Š Session Statistics:\")\n",
    "print(f\"  Total LLM calls: {final_metrics['totalRuns']}\")\n",
    "print(f\"  Average sourness: {final_metrics['averageSourness']:.4f}\")\n",
    "print(f\"  Success rate (sweet): {final_metrics['sweetRate']:.1%}\")\n",
    "print(f\"  Total hallucinations detected: {final_metrics['totalHallucinations']}\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Framework Capabilities Validated:\")\n",
    "print(\"  â†’ Production-grade error handling\")\n",
    "print(\"  â†’ Configurable thresholds and weights\")\n",
    "print(\"  â†’ Comprehensive validation\")\n",
    "print(\"  â†’ Token-level diagnostics\")\n",
    "print(\"  â†’ Automated corrections\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ¨ SourCandy Framework Test Complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caf988f",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Replace `YOUR_OPENROUTER_API_KEY_HERE` with your actual API key\n",
    "2. Customize the knowledge graph with your domain-specific entities\n",
    "3. Add your own factual documents to the knowledge store\n",
    "4. Adjust sourness thresholds based on your use case\n",
    "5. Configure domain verifiers for your specific domains\n",
    "6. Experiment with different weight combinations (w1, w2, w3)\n",
    "\n",
    "**Troubleshooting:**\n",
    "- If you get API errors, verify your OpenRouter API key is valid\n",
    "- Adjust `max_tokens` in the LLM wrapper if responses are truncated\n",
    "- Lower the sourness threshold if too many false positives\n",
    "- Increase the sourness threshold if missing hallucinations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
